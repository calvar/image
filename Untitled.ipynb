{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3ba87e7",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/introyt/trainingyt.html <br>\n",
    "Instalar: torch, torchvision, tensorboard, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c27b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c033fa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a94aa8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9de4485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a transform object that takes the data to pytorch tensor form and normalizes it\n",
    "transform = Compose( [ToTensor(), Normalize((0.5,),(0.5,))] );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d8135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Get the fashion mnist set of images, and create the train and test data sets\n",
    "training_set = FashionMNIST('./data', train=True, transform=transform, download=True);\n",
    "validation_set = FashionMNIST('./data', train=False, transform=transform, download=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ce26af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare batches that update at every epoch for training. Use multiprocessing\n",
    "training_loader = DataLoader(training_set, batch_size=4, shuffle=True, num_workers=2);\n",
    "validation_loader = DataLoader(validation_set, batch_size=4, shuffle=False, num_workers=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5262c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c6ef745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "#Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)));\n",
    "print('Validation set has {} instances'.format(len(validation_set)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c49fb6",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dbeb96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a3a0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an iterator to go through the training data\n",
    "dataiter = iter(training_loader);\n",
    "#Take the next minibatch of data\n",
    "images, labels = dataiter.next(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c6d30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag Shirt Coat Shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images);\n",
    "matplotlib_imshow(img_grid, one_channel=True);\n",
    "print(' '.join(classes[labels[j]] for j in range(4)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd786c",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c8a12b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) #Add a convolution layer thet resives a single layer as imput (grayscale), uses 6 filters on it, and each filter has 5x5 size\n",
    "        self.pool = nn.MaxPool2d(2,2) #Pooling layer. Operation to get the max value over 2x2 (stride 2) sections the filter and reduce the number of features\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) #Second convolution layer (6 chanel imput, from the 6 filters of previous layer, 16 filters, and 5x5 filter size)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120) #1st linear layer to classify the compressed features (why is imput 16*4*4?)\n",
    "        self.fc2 = nn.Linear(120, 84) #2nd linear layer\n",
    "        self.fc3 = nn.Linear(84, 10) #3rd linear layer. output is size 10 because there are 10 classes\n",
    "        \n",
    "    # Forward passing of the data\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # pass x input to conv layer 1 and apply relu to the result, then do pooling to reduce number of features?\n",
    "        x = self.pool(F.relu(self.conv2(x))) # then do the same using conv layer 2?\n",
    "        x = x.view(-1, 16*4*4) # flatten x from 2d to 1d??\n",
    "        x = F.relu(self.fc1(x)) #Apply relu to output of linear layer 1\n",
    "        x = F.relu(self.fc2(x)) #Apply relu to output of linear layer 2\n",
    "        x = self.fc3(x) #Pass output through layer 3 and get final result\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcbca866",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GarmentClassifier().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9f29b0",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d70428dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the log loss as cost function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8506f710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6669, 0.4861, 0.2850, 0.5124, 0.6673, 0.6141, 0.5433, 0.0650, 0.7657,\n",
      "         0.4428],\n",
      "        [0.6528, 0.3303, 0.9764, 0.3992, 0.2127, 0.0686, 0.4946, 0.7535, 0.8515,\n",
      "         0.6587],\n",
      "        [0.2078, 0.8101, 0.2161, 0.3659, 0.7789, 0.1699, 0.0241, 0.2891, 0.9297,\n",
      "         0.2692],\n",
      "        [0.4218, 0.7481, 0.6697, 0.7421, 0.1357, 0.8455, 0.6558, 0.5413, 0.5101,\n",
      "         0.9770]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batxh: 2.4874510765075684\n"
     ]
    }
   ],
   "source": [
    "##Test the loss function##\n",
    "#Pass data in batches of 4\n",
    "#Returns 10 lists of 4 random numbers between 0 and 1 as a 4x10 tensor, to test confidence on each of the 10 classes\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# Represents the correct class among the possible 10\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "\n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total loss for this batxh: {}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855b5e0a",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "791a1ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic gradient descent optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c792a7b",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "- Get a batch of data from the Data Loader\n",
    "- Zero the optimizer's gradients\n",
    "- Gets predictions from the model for an imput batch\n",
    "- Computes the loss function for the prediction\n",
    "- Adjusts the model's weights with gradient descent\n",
    "- Reports the loss for every 1000 batches\n",
    "- Reports the average per-batch loss for the last 1000 batches for comparison to a validation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb14913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "    \n",
    "    #Use an enumeration istead of an iterator to track the batch index and do reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        #training instances are input + label pairs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        #zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #make predictions fo this batch\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        #compute loss and its gradient\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        #adjust the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        #gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 #loss per batch\n",
    "            print(' batch {} loss: {}'.format(i+1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0\n",
    "            \n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e50fda8",
   "metadata": {},
   "source": [
    "## Main loop\n",
    "Before training an epoch there are a couple of things to do:\n",
    "- Validate by checking the relative loss on a set of validation data and report it\n",
    "- Save a copy of the model\n",
    "\n",
    "We use TensorBoard to do the reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f6d2f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6480a378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      " batch 1000 loss: 0.41282334006595195\n",
      " batch 2000 loss: 0.41481274314859184\n",
      " batch 3000 loss: 0.3759617363713624\n",
      " batch 4000 loss: 0.39644522705033886\n",
      " batch 5000 loss: 0.3848450304780854\n",
      " batch 6000 loss: 0.3923068636279495\n",
      " batch 7000 loss: 0.38416296596697064\n",
      " batch 8000 loss: 0.373133598024433\n",
      " batch 9000 loss: 0.3842620130462456\n",
      " batch 10000 loss: 0.37001189577113835\n",
      " batch 11000 loss: 0.37540785296307877\n",
      " batch 12000 loss: 0.37083178940918876\n",
      " batch 13000 loss: 0.3509974839552888\n",
      " batch 14000 loss: 0.3624207211101602\n",
      " batch 15000 loss: 0.3619138792199119\n",
      "LOSS train 0.3619138792199119 valid 0.3697698712348938\n",
      "EPOCH 2\n",
      " batch 1000 loss: 0.3574868578981841\n",
      " batch 2000 loss: 0.3275362235512002\n",
      " batch 3000 loss: 0.3232526590783964\n",
      " batch 4000 loss: 0.3359705314456951\n",
      " batch 5000 loss: 0.3521081158304296\n",
      " batch 6000 loss: 0.34864866882107165\n",
      " batch 7000 loss: 0.3191806119563553\n",
      " batch 8000 loss: 0.3241248514439503\n",
      " batch 9000 loss: 0.3071584889641963\n",
      " batch 10000 loss: 0.3163393999084583\n",
      " batch 11000 loss: 0.32349962480092653\n",
      " batch 12000 loss: 0.3155585376047061\n",
      " batch 13000 loss: 0.32762964354098223\n",
      " batch 14000 loss: 0.3306849645425973\n",
      " batch 15000 loss: 0.3187899070154872\n",
      "LOSS train 0.3187899070154872 valid 0.34796568751335144\n",
      "EPOCH 3\n",
      " batch 1000 loss: 0.3155871006935376\n",
      " batch 2000 loss: 0.29934744375738953\n",
      " batch 3000 loss: 0.31074388507939876\n",
      " batch 4000 loss: 0.30035485345928464\n",
      " batch 5000 loss: 0.3022793189761724\n",
      " batch 6000 loss: 0.2990907435883564\n",
      " batch 7000 loss: 0.3081842132105521\n",
      " batch 8000 loss: 0.3113479313054195\n",
      " batch 9000 loss: 0.29246065829807777\n",
      " batch 10000 loss: 0.29347085486337166\n",
      " batch 11000 loss: 0.3089590744117195\n",
      " batch 12000 loss: 0.2979382919056752\n",
      " batch 13000 loss: 0.27982586524692304\n",
      " batch 14000 loss: 0.31541567636332185\n",
      " batch 15000 loss: 0.297173707573842\n",
      "LOSS train 0.297173707573842 valid 0.35880208015441895\n",
      "EPOCH 4\n",
      " batch 1000 loss: 0.28007419021012175\n",
      " batch 2000 loss: 0.2841478447507834\n",
      " batch 3000 loss: 0.2702042152569229\n",
      " batch 4000 loss: 0.2648019396700438\n",
      " batch 5000 loss: 0.29019116524271704\n",
      " batch 6000 loss: 0.3012522768218332\n",
      " batch 7000 loss: 0.28122577781375\n",
      " batch 8000 loss: 0.2597823919958041\n",
      " batch 9000 loss: 0.2790391664596973\n",
      " batch 10000 loss: 0.2878904949462958\n",
      " batch 11000 loss: 0.29117026040914606\n",
      " batch 12000 loss: 0.3014209887710822\n",
      " batch 13000 loss: 0.27467369006919035\n",
      " batch 14000 loss: 0.3053269638926795\n",
      " batch 15000 loss: 0.2640177806774445\n",
      "LOSS train 0.2640177806774445 valid 0.33297109603881836\n",
      "EPOCH 5\n",
      " batch 1000 loss: 0.25800588595234875\n",
      " batch 2000 loss: 0.28180268165142297\n",
      " batch 3000 loss: 0.24415492093039665\n",
      " batch 4000 loss: 0.2547222062660221\n",
      " batch 5000 loss: 0.28549087479249285\n",
      " batch 6000 loss: 0.2734396648898173\n",
      " batch 7000 loss: 0.25143381662933095\n",
      " batch 8000 loss: 0.26603276835624273\n",
      " batch 9000 loss: 0.2734131964925546\n",
      " batch 10000 loss: 0.2688249423810048\n",
      " batch 11000 loss: 0.27093010440340004\n",
      " batch 12000 loss: 0.28150122510475556\n",
      " batch 13000 loss: 0.27814316229472025\n",
      " batch 14000 loss: 0.2610784416458164\n",
      " batch 15000 loss: 0.27460218369924405\n",
      "LOSS train 0.27460218369924405 valid 0.3150368630886078\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}'.format(epoch_number + 1))\n",
    "    \n",
    "    #Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "    \n",
    "    #To do reporting gradients do not need to be on\n",
    "    model.train(False)\n",
    "    \n",
    "    #Pull batches fron validation data to validate\n",
    "    running_vloss = 0\n",
    "    for i, vdata in enumerate(validation_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "    \n",
    "    avg_vloss = running_vloss / (i+1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "    \n",
    "    ##Log the runnig loss averaged per batch for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                      {'Training': avg_loss, 'Validation': avg_vloss},\n",
    "                      epoch_number + 1)\n",
    "    writer.flush()\n",
    "    \n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "    epoch_number += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "023cd906",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#To load the saved version of the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m GarmentClassifier()\n\u001b[0;32m----> 3\u001b[0m saved_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[43mPATH\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PATH' is not defined"
     ]
    }
   ],
   "source": [
    "#To load the saved version of the model\n",
    "saved_model = GarmentClassifier()\n",
    "saved_model.load_state_dict(torch.load(./model_2022))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
